# Complete Flow Diagram: Master Orchestrator to BigQuery Output

## ðŸŽ¯ **Overview**

This diagram traces the complete flow from the master orchestrator through all components to the final BigQuery output, including error handling and recovery scenarios.

## ðŸ“Š **Complete Flow Diagram**

```mermaid
graph TD
    %% Start
    A[ðŸŽ¯ Master Orchestrator Workflow] --> B[ðŸ“‹ Initialize Parameters]
    B --> C[ðŸ”¢ Get Total Records from BigQuery]
    C --> D[ðŸ“ Create Batch Plan]
    
    
    %% Initial Batch Launch
    D --> F[ðŸš€ Start Initial Batches]
    F --> G[ðŸ”„ Launch ta-sub-workflow Sub-workflows]
    
    %% Individual Batch Workflow
    G --> H[ðŸ“ ta-sub-workflow Sub-workflow]
    H --> I[ðŸ“¤ Call pass1-batch-generator Function]
    
    %% Batch Generator
    I --> J{ðŸ” Query BigQuery with Deduplication}
    J --> K[ðŸ“„ Generate JSONL Batch File]
    K --> L[â˜ï¸ Upload to GCS Bucket]
    
    %% Vertex AI Batch Prediction
    L --> M[ðŸ¤– Submit Vertex AI Batch Prediction Job]
    M --> N[â³ Poll Job Status]
    N --> O{â“ Job Status?}
    
    %% Job Success Path
    O -->|âœ… SUCCEEDED| P[ðŸ“¥ Download Results from GCS]
    O -->|âŒ FAILED| Q[ðŸ’¥ Batch Job Failed]
    O -->|â¸ï¸ CANCELLED| R[ðŸš« Batch Job Cancelled]
    O -->|â³ RUNNING| N
    
    %% Batch Processor
    P --> S[ðŸ“¤ Call pass1-batch-processor Function]
    S --> T[ðŸ” Parse Vertex AI Responses]
    T --> U[ðŸ“Š Insert Results to BigQuery]
    
    %% Success Tracking
    U --> V[âœ… Update processed_records Table]
    V --> W[ðŸ“ Track Individual Errors]
    W --> X[ðŸ“ˆ Report Completion to batch-orchestrator]
    
    
    %% Error Scenarios
    
    R --> AA[ðŸ“Š Batch Status = 'failed']
    
    %% Individual Record Errors
    W --> BB{â“ Any Record Errors?}
    BB -->|âœ… Yes| CC[ðŸ“ Insert to error_tracking Table]
    BB -->|âŒ No| X
    CC --> X
    
    %% Monitoring Loop
    X --> DD[ðŸ”„ Monitor and Continue Loop]
    DD --> EE[ðŸ” Check Batch Statuses via batch-orchestrator]
    
    
    
    
    %% Completion
    X --> II{â“ All Batches Complete?}
    II -->|âŒ No| DD
    II -->|âœ… Yes| JJ[ðŸ“Š Generate Summary Report]
    JJ --> KK[ðŸŽ‰ Master Orchestrator Complete]
    
    %% Recovery Scenarios
    AA --> LL[ðŸ”„ Recovery: Reprocess Failed Batch]
    LL --> H
    
    %% Styling
    classDef success fill:#d4edda,stroke:#155724,stroke-width:2px,color:#155724
    classDef error fill:#f8d7da,stroke:#721c24,stroke-width:2px,color:#721c24
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    classDef decision fill:#fff3cd,stroke:#856404,stroke-width:2px,color:#856404
    classDef storage fill:#e2e3e5,stroke:#383d41,stroke-width:2px,color:#383d41
    
    class A,B,C,D,F,G,H,I,J,K,L,M,N,P,S,T,U,V,W,X,JJ,KK process
    class O,BB,II decision
    class Q,R,AA,CC error
    class DD,EE,LL success
    class C,D,V,W,X,CC storage
```

## ðŸ”„ **Detailed Component Flow**

### **1. Master Orchestrator Workflow**
```mermaid
graph LR
    A[ðŸŽ¯ Master Orchestrator] --> B[ðŸ“‹ Initialize]
    B --> C[ðŸ”¢ Get Total Records]
    C --> D[ðŸ“ Create Batch Plan]
    D --> E[ðŸš€ Start Initial Batches]
    E --> F[ðŸ”„ Monitor Loop]
    F --> G[ðŸ“Š Generate Summary]
    
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    class A,B,C,D,E,F,G process
```

### **2. Individual Batch Workflow**
```mermaid
graph LR
    A[ðŸ“ ta-sub-workflow] --> B[ðŸ“¤ Generate Batch]
    B --> C[ðŸ¤– Vertex AI Job]
    C --> D[ðŸ“¥ Process Results]
    D --> E[ðŸ“Š Update Tracking]
    
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    class A,B,C,D,E process
```

### **3. Error Handling Flow**
```mermaid
graph TD
    A[âŒ Error Occurs] --> B{â“ Error Type?}
    
    B -->|Record Level| D[ðŸ“ Insert to error_tracking]
    B -->|System Level| E[ðŸš¨ Log and Alert]
    
    C --> F[ðŸ”„ Mark Batch for Reprocessing]
    D --> G[ðŸ” Debug Systemic Issues]
    E --> H[âš¡ Immediate Action Required]
    
    classDef error fill:#f8d7da,stroke:#721c24,stroke-width:2px,color:#721c24
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    classDef decision fill:#fff3cd,stroke:#856404,stroke-width:2px,color:#856404
    
    class A,C,D,E,F,G,H error
    class B decision
```

## ðŸ“Š **Data Flow Between Components**

### **BigQuery Tables Interaction**
```mermaid
graph TD
    A[ðŸ“Š transcription_pass_2] --> B[ðŸ“¤ pass1-batch-generator]
    B --> C[ðŸ“„ JSONL File]
    C --> D[ðŸ¤– Vertex AI]
    D --> E[ðŸ“¥ pass1-batch-processor]
    E --> F[ðŸ“Š transcription_analyzed_transcripts]
    
    
    H --> G
    
    I[ðŸ“Š processed_records] --> B
    E --> I
    
    J[ðŸ“Š error_tracking] --> E
    
    classDef storage fill:#e2e3e5,stroke:#383d41,stroke-width:2px,color:#383d41
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    
    class A,F,G,I,J storage
    class B,C,D,E,H process
```

## ðŸš¨ **Error Scenarios and Recovery**

### **Scenario 1: Batch Job Failure**
```mermaid
graph LR
    A[ðŸ¤– Vertex AI Job] --> B[âŒ FAILED]
    B --> C[ðŸ’¾ Status: 'failed']
    C --> D[ðŸ”„ Recovery: Reprocess Batch]
    D --> A
    
    classDef error fill:#f8d7da,stroke:#721c24,stroke-width:2px,color:#721c24
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    
    class B,C error
    class A,D process
```

### **Scenario 2: Individual Record Errors**
```mermaid
graph LR
    A[ðŸ“¥ Parse Response] --> B[âŒ JSON Parse Error]
    A --> C[âŒ Missing Summary]
    A --> D[âŒ Vertex AI Error]
    
    B --> E[ðŸ“ error_tracking: 'json_parse_error']
    C --> F[ðŸ“ error_tracking: 'missing_summary']
    D --> G[ðŸ“ error_tracking: 'vertex_ai_error']
    
    E --> H[ðŸ” Debug Systemic Issues]
    F --> H
    G --> H
    
    classDef error fill:#f8d7da,stroke:#721c24,stroke-width:2px,color:#721c24
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    
    class B,C,D,E,F,G error
    class A,H process
```

### **Scenario 3: Cloud Function Timeout**
```mermaid
graph LR
    A[ðŸ“¤ Cloud Function Call] --> B[â° Timeout]
    B --> C[ðŸ”„ Retry Logic]
    C --> D{â“ Max Retries?}
    D -->|âŒ No| A
    D -->|âœ… Yes| E[ðŸ’¾ Mark as Failed]
    E --> F[ðŸ”„ Manual Recovery Required]
    
    classDef error fill:#f8d7da,stroke:#721c24,stroke-width:2px,color:#721c24
    classDef process fill:#d1ecf1,stroke:#0c5460,stroke-width:2px,color:#0c5460
    classDef decision fill:#fff3cd,stroke:#856404,stroke-width:2px,color:#856404
    
    class B,E,F error
    class A,C process
    class D decision
```

## ðŸ“ˆ **Monitoring and Progress Tracking**

### **Real-time Monitoring Queries**
```sql


-- Error Analysis
SELECT 
    error_type,
    COUNT(*) as error_count
FROM error_tracking
WHERE created_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
GROUP BY error_type
ORDER BY error_count DESC;


```

## ðŸŽ¯ **Key Success Metrics**

- âœ… **Batch Success Rate**: Percentage of batches completed successfully
- âœ… **Processing Rate**: Batches processed per hour
- âœ… **Error Rate**: Percentage of records with processing errors
- âœ… **Deduplication Rate**: Percentage of records skipped due to prior processing
- âœ… **Recovery Time**: Time to identify and reprocess failed batches

## ðŸ”§ **Recovery Commands**

```bash


# Reprocess failed batch
gcloud workflows execute ta-sub-workflow \
  --data='{"start_row": 1, "end_row": 10000, "execution_id": "recovery_123"}'

# Clear processing history for complete reprocessing
bq query --use_legacy_sql=false "
DELETE FROM processed_records 
WHERE first_processed_execution_id = 'old_execution_id'
"
```

This comprehensive flow diagram shows the complete journey from master orchestrator to final BigQuery output, including all error scenarios and recovery mechanisms!
